{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value analysis\n",
    "\n",
    "Missing Completely at Random:  There is no pattern in the missing data on any variables. This is the best you can hope for.\n",
    "\n",
    "Missing at Random: There is a pattern in the missing data but not on your primary dependent variables such as likelihood to recommend or SUS Scores.\n",
    "\n",
    "Missing Not at Random: There is a pattern in the missing data that affect your primary dependent variables. For example, lower-income participants are less likely to respond and thus affect your conclusions about income and likelihood to recommend. \n",
    "\n",
    "Missing not at random is your worst-case scenario. Proceed with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "full_training_set = pandas.read_csv('data/training_set_VU_DM_2014.csv')\n",
    "print(\"Dataset loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the dataset a plot can be shown analyse the missing values. With the help of missingno a interesting plot is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_missing_columns = [\"srch_id\"]\n",
    "# for index_val, val in zip(list_of_missing_data.index,list_of_missing_data):\n",
    "#     if val > 0 and index_val != \"gross_bookings_usd\":\n",
    "#         list_missing_columns.append(index_val)\n",
    "\n",
    "\n",
    "msno.matrix(full_training_set, labels=list(full_training_set))\n",
    "plt.savefig('matrix.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(full_training_set, labels=list(full_training_set))\n",
    "plt.savefig('heat.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(full_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_training_set.describe().to_csv('D:/Users/Thomas/Documents/GitHub/dmt_assignment_2/describe.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the amount of missing values in the dataset gives an insight if values should be removed Entirely or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_missing_data = full_training_set.isnull().sum()\n",
    "print(list_of_missing_data)\n",
    "i = 0\n",
    "for index_val, val in zip(list_of_missing_data.index,list_of_missing_data):\n",
    "    if val > 0:\n",
    "        i += 1\n",
    "print(\"Amount of columns with missing values: \"+ str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-tests are used to figure out if the data is completely at random and thus the entire column can be removed. When there is a definitive correlation between the to predict values click_bool and/or booking_bool the missing values have to be filled in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average for clicking \" +str(full_training_set['click_bool'].mean()))\n",
    "\n",
    "\n",
    "print(\"average for booking \" +str(full_training_set['booking_bool'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "z_score, p_value = sm.stats.proportions_ztest([135, 47], [1781, 1443])\n",
    "\n",
    "for index_val, val in zip(list_of_missing_data.index,list_of_missing_data):\n",
    "    # If there is missing data we can do a t-test.\n",
    "    if val > 0 and index_val != \"gross_bookings_usd\":\n",
    "        print(index_val)\n",
    "        cat1 = full_training_set[full_training_set[index_val].isnull()==True]['click_bool']\n",
    "        cat2 = full_training_set[full_training_set[index_val].isnull()==False]['click_bool']\n",
    "        cat1mean = cat1.mean()\n",
    "        cat2mean = cat2.mean()\n",
    "\n",
    "        if cat1mean > cat2mean:\n",
    "            print(\"more likely to click with NULL \" + str(cat1mean) + \" > \" + str(cat2mean))\n",
    "        else:\n",
    "            print(\"Less likely to click with NULL \" + str(cat1mean) + \" < \" + str(cat2mean))        \n",
    "#         print(\"average for null values: \"+ str(cat1.mean()))\n",
    "#         print(\"average for not null values: \"+ str(cat2.mean()))\n",
    "            \n",
    "#         t2, p2 = stats.ttest_ind(cat1,cat2,equal_var=False)\n",
    "#         print(\"t-value click boolean = \" + str(t2))\n",
    "#         print(\"p-value click boolean = \" + str(p2))\n",
    "        \n",
    "        cat1 = full_training_set[full_training_set[index_val].isnull()==True]['booking_bool']\n",
    "        cat2 = full_training_set[full_training_set[index_val].isnull()==False]['booking_bool']\n",
    "        cat1mean = cat1.mean()\n",
    "        cat2mean = cat2.mean()\n",
    "        if cat1mean > cat2mean:\n",
    "            print(\"more likely to book with NULL \" + str(cat1mean) + \" > \" + str(cat2mean))\n",
    "        else:\n",
    "            print(\"Less likely to book with NULL \" + str(cat1mean) + \" < \" + str(cat2mean))   \n",
    "#         print(\"average for null values: \"+ str(cat1mean))\n",
    "#         print(\"average for not null values: \"+ str(cat1mean))\n",
    "#         t2, p2 = stats.ttest_ind(cat1,cat2,equal_var=False)\n",
    "#         print(\"t-value booking boolean = \" + str(t2))\n",
    "#         print(\"p-value booking boolean = \" + str(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_val, val in zip(list_of_missing_data.index,list_of_missing_data):\n",
    "    # If there is missing data we can do a t-test.\n",
    "    if val > 0 and index_val != \"gross_bookings_usd\":\n",
    "        print(index_val)\n",
    "        cat2 = full_training_set[full_training_set[index_val].isnull()==False][index_val]\n",
    "\n",
    "        print(\"new average for null values: \"+ str(cat2.mean()))\n",
    "        print(\"min for null values: \"+ str(cat2.min()))\n",
    "        print(\"max for null values: \"+ str(cat2.max()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# full_training_set['max_rate_percent_diff'] = full_training_set[['comp1_rate_percent_diff', 'comp2_rate_percent_diff', \n",
    "#                                                                 'comp3_rate_percent_diff', 'comp4_rate_percent_diff', \n",
    "#                                                                 'comp5_rate_percent_diff', 'comp6_rate_percent_diff', \n",
    "#                                                                 'comp7_rate_percent_diff', 'comp8_rate_percent_diff'] \n",
    "#                                                               ].max(axis=0)\n",
    "\n",
    "# full_training_set['min_rate_percent_diff'] = full_training_set[['comp1_rate_percent_diff', 'comp2_rate_percent_diff', \n",
    "#                                                                 'comp3_rate_percent_diff', 'comp4_rate_percent_diff', \n",
    "#                                                                 'comp5_rate_percent_diff', 'comp6_rate_percent_diff', \n",
    "#                                                                 'comp7_rate_percent_diff', 'comp8_rate_percent_diff'] \n",
    "#                                                               ].min(axis=0)\n",
    "\n",
    "# full_training_set['count_available'] = 0.0\n",
    "# full_training_set['count_higher_rate'] = 0.0\n",
    "# full_training_set['count_lower_rate'] = 0.0\n",
    "# for elem in range(1,9):\n",
    "#     full_training_set['count_lower_rate'] += np.where(full_training_set['comp'+str(elem)+'_rate'] == -1, 1, 0)\n",
    "#     full_training_set['count_higher_rate'] += np.where(full_training_set['comp'+str(elem)+'_rate'] == 1, 1, 0)\n",
    "#     full_training_set['count_available'] += np.where(full_training_set['comp'+str(elem)+'_inv'] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_set.loc[:,'price_usd'] =  full_training_set['price_usd'].clip(lower=0.0, upper=1000.0)\n",
    "\n",
    "hist = full_training_set.drop(['srch_id', 'site_id',\n",
    " 'date_time',\n",
    " 'random_bool',\n",
    " 'promotion_flag',\n",
    " 'prop_brand_bool',\n",
    " 'srch_saturday_night_bool',\n",
    " 'comp1_rate',\n",
    " 'comp1_inv',\n",
    " 'comp1_rate_percent_diff',\n",
    " 'comp2_rate',\n",
    " 'comp2_inv',\n",
    " 'comp2_rate_percent_diff',\n",
    " 'comp3_rate',\n",
    " 'comp3_inv',\n",
    " 'comp3_rate_percent_diff',\n",
    " 'comp4_rate',\n",
    " 'comp4_inv',\n",
    " 'comp4_rate_percent_diff',\n",
    " 'comp5_rate',\n",
    " 'comp5_inv',\n",
    " 'comp5_rate_percent_diff',\n",
    " 'comp6_rate',\n",
    " 'comp6_inv',\n",
    " 'comp6_rate_percent_diff',\n",
    " 'comp7_rate',\n",
    " 'comp7_inv',\n",
    " 'comp7_rate_percent_diff',\n",
    " 'comp8_rate',\n",
    " 'comp8_inv',\n",
    " 'comp8_rate_percent_diff',\n",
    " 'click_bool',\n",
    " 'gross_bookings_usd',\n",
    " 'booking_bool'],axis=1).hist(figsize=(30,24),layout=(8,7),bins=20)\n",
    "\n",
    "\n",
    "plt.savefig('hist_clean.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = full_training_set.hist(figsize=(30,24),layout=(8,7),bins=20)\n",
    "\n",
    "\n",
    "plt.savefig('hist.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat2 = full_training_set[full_training_set['count_available'].isnull()==False]['count_available']\n",
    "\n",
    "# print(full_training_set['count_available'].head(5))\n",
    "# print(\"min for null values: \"+ str(cat2.min()))\n",
    "# print(\"max for null values: \"+ str(cat2.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "z_score, p_value = sm.stats.proportions_ztest([135, 47], [1781, 1443])\n",
    "\n",
    "for index_val, val in zip(list_of_missing_data.index,list_of_missing_data):\n",
    "    # If there is missing data we can do a t-test.\n",
    "    if val > 0 and index_val != \"gross_bookings_usd\":\n",
    "        cat1 = full_training_set[full_training_set[index_val].isnull()==True]['click_bool']\n",
    "        cat2 = full_training_set[full_training_set[index_val].isnull()==False]['click_bool']\n",
    "        \n",
    "        z_score, p_value = sm.stats.proportions_ztest([cat1.sum(), cat2.sum()], [cat1.count(), cat2.count()]) \n",
    "        print(index_val + \" click proportion likelihood : \" + str(stats.norm.cdf(z_score)) )\n",
    "        \n",
    "        cat1 = full_training_set[full_training_set[index_val].isnull()==True]['booking_bool']\n",
    "        cat2 = full_training_set[full_training_set[index_val].isnull()==False]['booking_bool']\n",
    "\n",
    "        z_score, p_value = sm.stats.proportions_ztest([cat1.sum(), cat2.sum()], [cat1.count(), cat2.count()]) \n",
    "        print(index_val + \" book proportion likelihood : \" + str(stats.norm.cdf(z_score)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = full_training_set.boxplot(grid=False, rot=90, fontsize=8)\n",
    "plt.savefig('box.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = full_training_set.min()\n",
    "max_val = full_training_set.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_set.fillna(-400)\n",
    "for elem in list(full_training_set):\n",
    "    if elem == \"date_time\":\n",
    "        pass\n",
    "    else:\n",
    "        full_training_set[elem] = (full_training_set[elem]-min_val[elem])/(max_val[elem]-min_val[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_training_set = full_training_set.mask(full_training_set < 0)\n",
    "boxplot = full_training_set.drop(['srch_id', 'site_id',\n",
    " 'date_time',\n",
    " 'random_bool',\n",
    " 'comp1_rate',\n",
    " 'comp1_inv',\n",
    " 'comp1_rate_percent_diff',\n",
    " 'comp2_rate',\n",
    " 'comp2_inv',\n",
    " 'comp2_rate_percent_diff',\n",
    " 'comp3_rate',\n",
    " 'comp3_inv',\n",
    " 'comp3_rate_percent_diff',\n",
    " 'comp4_rate',\n",
    " 'comp4_inv',\n",
    " 'comp4_rate_percent_diff',\n",
    " 'comp5_rate',\n",
    " 'comp5_inv',\n",
    " 'comp5_rate_percent_diff',\n",
    " 'comp6_rate',\n",
    " 'comp6_inv',\n",
    " 'comp6_rate_percent_diff',\n",
    " 'comp7_rate',\n",
    " 'comp7_inv',\n",
    " 'comp7_rate_percent_diff',\n",
    " 'comp8_rate',\n",
    " 'comp8_inv',\n",
    " 'comp8_rate_percent_diff',\n",
    " 'click_bool',\n",
    " 'gross_bookings_usd',\n",
    " 'booking_bool'],axis=1).boxplot(grid=False, rot=90, fontsize=8)\n",
    "plt.savefig('box_norm_miss.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = full_training_set.boxplot(grid=False, rot=90, fontsize=8)\n",
    "plt.savefig('box_norm.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation\n",
    "\n",
    "corr_matrix = full_training_set.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(full_training_set.corr(), interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ax.set_xticklabels(['']+list(full_training_set))\n",
    "ax.set_yticklabels(['']+list(full_training_set))\n",
    "\n",
    "plt.savefig('corr.png', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr_matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(30, 22))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=0.4, center=0,\n",
    "            square=True, linewidths=.25, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "plt.savefig('corr.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
